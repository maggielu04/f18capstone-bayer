{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "import csv\n",
    "from fractions import Fraction\n",
    "import builtins\n",
    "\n",
    "\n",
    "######### see Lab3 ###############\n",
    "def get_text_from_elements(elements):\n",
    "    \"\"\"Uses list comprehension to parse out the cleaned text strings from a list of\n",
    "    elements returned from a BeautifulSoup selection.\n",
    "\n",
    "    Arguments:\n",
    "        elements {list} -- list of elements returned from a BeautifulSoup selection\n",
    "\n",
    "    Returns:\n",
    "        list -- list of cleaned text contained within the element list\n",
    "    \"\"\"\n",
    "    return [e.text.strip() for e in elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_urls = list()\n",
    "for i in range(1,36,1):\n",
    "    jour_urls.append(\"https://pubs.acs.org/toc/jacsat/140/\"+ str(i))\n",
    "#print(jour_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put'em in a list\n",
    "art_urls = list()\n",
    "\n",
    "#Disabling JavaScript loading to speed up the process\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option( \"prefs\",{'profile.managed_default_content_settings.javascript': 2})\n",
    "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "for url in jour_urls:\n",
    "    browser.get(url)\n",
    "    #data = r.text\n",
    "    time.sleep(5)\n",
    "    soup = bs(browser.page_source, 'html.parser')\n",
    "    for link in soup.find_all('a'):\n",
    "    #print(link)\n",
    "    #regular expression\n",
    "        n = re.search('/doi/abs/', str(link.get('href')))\n",
    "        if not pd.isnull(n):\n",
    "        #print(str(link.get('href')))\n",
    "            art_urls.append(\"https://pubs.acs.org\"+str(link.get('href')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test run\n",
    "sub_art_list = art_urls[0:100]\n",
    "\n",
    "title_list = list()\n",
    "authors_list = list()\n",
    "text_list = list()\n",
    "\n",
    "title_list.append('Title')\n",
    "authors_list.append('Authors')\n",
    "text_list.append('Abstract')\n",
    "\n",
    "#Disabling JavaScript loading to speed up the process\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option( \"prefs\",{'profile.managed_default_content_settings.javascript': 2})\n",
    "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "for url in sub_art_list:\n",
    "    browser.get(url)\n",
    "    #data = r.text\n",
    "    time.sleep(5)\n",
    "    soup = bs(browser.page_source, 'html.parser')\n",
    "    title = get_text_from_elements(soup.select(\"h1.articleTitle\"))[0]\n",
    "    title_list.append(title)\n",
    "    authors = get_text_from_elements(soup.select(\"a#authors\"))\n",
    "    authors_list.append(authors)\n",
    "    textblock = get_text_from_elements(soup.select(\"p.articleBody_abstractText\")) \n",
    "    text_list.append(textblock)\n",
    "\n",
    "rows = zip(title_list,authors_list,text_list)\n",
    "\n",
    "import csv\n",
    "with open(\"list.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
